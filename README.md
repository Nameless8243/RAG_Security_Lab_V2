# RAG Security Lab V2

A multi-layer defensive lab demonstrating **enterprise-grade security controls** for RAG ingestion pipelines:

- Lineage & integrity verification (hash + signature)
- Semantic anomaly detection (poisoning, drift)
- Multi-stage quarantine workflow
- Tamper-evident audit log (hash-chain)
- Full adversarial attack simulation

This lab shows how to secure document pipelines *before* data reaches LLMs.

---

## ğŸ— Architecture Overview

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Document Ingestion    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Lineage Verifier     â”‚
              â”‚  (hash + signature)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Semantic Scanner     â”‚
              â”‚ (poisoning & drift)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Quarantine Manager    â”‚
              â”‚  (evidence bundling)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Audit Log (Hash-Chain) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each layer blocks a different attack surface.

---

## ğŸ§© Requirements

```
numpy
sentence-transformers
torch
```

> *Note:* The default torch package installed via pip is the CPU-only version (lightweight, no GPU required). 
> If you want GPU acceleration, install a CUDA-enabled PyTorch build manually.

---

## ğŸ›  Installation

```
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ§ª Full Attack Simulation

**Run:**

```
python3 -m simulations.full_attack_simulation
```

**Example output:**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   RAG SECURITY LAB V2 â€“ FULL ATTACK SIMULATION REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Timestamp: 2025-12-02T15:45:56Z

[OK] doc-clean                ACCEPTED

[!] doc-lineage-attack        QUARANTINED (blocked: lineage)
     evidence: data/quarantine/...

[!] doc-semantic-attack       QUARANTINED (blocked: semantic)
     evidence: data/quarantine/...

[!] doc-combined-attack       QUARANTINED (blocked: lineage)
     evidence: data/quarantine/...

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total documents    : 4
 Accepted           : 1
 Quarantined        : 3
 Lineage blocked    : 2
 Semantic blocked   : 1

 Audit log          : data/audit/audit_log.jsonl
 Quarantine folder  : data/quarantine/
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

Evidence bundles and audit logs are automatically generated:

- `data/audit/audit_log.jsonl`
- `data/quarantine/...`

---

## ğŸ§¹ Cleanup Utility (reset_data.py)

A helper script is included to wipe all runtime data.

Run:
python3 simulations/reset_data.py

This deletes:
- data/audit/*
- data/quarantine/*

Useful for rerunning the full attack simulation from a clean state.

---

## ğŸ“‚ Project Structure

```
RAG_SECURITY_LAB_V2/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ audit/
â”‚   â””â”€â”€ quarantine/
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ audit/
â”‚   â”œâ”€â”€ lineage/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ quarantine/
â”‚   â””â”€â”€ semantic/
â”œâ”€â”€ simulations/
â”‚   â””â”€â”€ full_attack_simulation.py
â”‚   â””â”€â”€ reset_data.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---


## ğŸ›¡ Recommended Use Cases

This project is intended for **enterprise LLM security architectures**, including:

- **Secure RAG Ingestion Pipelines**  
  Hardening document intake before embedding or retrieval.

- **AI Supply Chain Security Controls**  
  Ensuring integrity, authenticity, and tamper-evidence for ingested content.

- **Content Integrity Enforcement**  
  Detecting manipulation, poisoning, and semantic drift.

- **Governance, Risk & Compliance (GRC)**  
  Tamper-evident auditability for regulated AI environments.

- **Threat Modeling & Architecture**  
  Demonstrating defensive layers against RAG poisoning and lineage attacks.

This aligns with emerging frameworks such as **NIST AI RMF** and **ISO/IEC 42001**.

---

## âš ï¸ Disclaimer

This project is provided for **educational and research purposes only**.  
It is **not** intended to be used as a production security control without additional
hardening, validation, and organization-specific review.

The authors and contributors provide this software **â€œas isâ€ without warranty** of any kind,
express or implied, including but not limited to fitness for a particular purpose,  
security guarantees, or compliance with regulatory requirements.

Use this project **at your own risk**.

---

## ğŸ“œ License

MIT License
